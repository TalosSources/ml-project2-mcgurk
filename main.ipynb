{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from experiments import McGurkExperiment\n",
    "\n",
    "# Instantiate the list of experiments\n",
    "experiments = [\n",
    "    McGurkExperiment(\"ba\", \"ga\", \"da\"), # ba (auditory) + ga (visual) = da  (fusioned sound)\n",
    "    McGurkExperiment(\"ba\", \"fa\", \"va\"), # ba (auditory) + fa (visual) = va  (fusioned sound)\n",
    "    McGurkExperiment(\"ga\", \"ba\", \"bga\") # ga (auditory) + ba (visual) = bga (combined sound)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression: input_dim=512, output_dim=3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                               "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrongly classified videos:\n",
      "dataset/train/da/da_jad_2.avi : tensor([4.5973e-01, 5.4027e-01, 9.9527e-40], grad_fn=<SelectBackward0>)\n",
      "dataset/train/da/da_jad_3.avi : tensor([4.7272e-01, 5.2728e-01, 6.6618e-40], grad_fn=<SelectBackward0>)\n",
      "dataset/train/da/da_jad_1.avi : tensor([0.4700, 0.5300, 0.0000], grad_fn=<SelectBackward0>)\n",
      "dataset/train/da/da_jad_4.avi : tensor([4.6805e-01, 5.3195e-01, 1.2564e-38], grad_fn=<SelectBackward0>)\n",
      "dataset/train/da/da_jad_5.avi : tensor([4.8847e-01, 5.1153e-01, 1.6084e-37], grad_fn=<SelectBackward0>)\n",
      "dataset/train/da/da_jad_7.avi : tensor([4.6097e-01, 5.3903e-01, 3.2591e-34], grad_fn=<SelectBackward0>)\n",
      "dataset/train/da/da_jad_6.avi : tensor([4.5400e-01, 5.4600e-01, 2.6518e-35], grad_fn=<SelectBackward0>)\n",
      "dataset/train/da/da_jad_18.avi : tensor([4.7059e-01, 5.2941e-01, 1.4372e-32], grad_fn=<SelectBackward0>)\n",
      "dataset/train/da/da_jad_19.avi : tensor([4.6053e-01, 5.3947e-01, 1.0844e-34], grad_fn=<SelectBackward0>)\n",
      "dataset/train/da/da_jad_17.avi : tensor([4.3407e-01, 5.6593e-01, 1.9672e-31], grad_fn=<SelectBackward0>)\n",
      "dataset/train/da/da_jad_16.avi : tensor([4.7553e-01, 5.2447e-01, 2.1797e-32], grad_fn=<SelectBackward0>)\n",
      "dataset/train/da/da_jad_14.avi : tensor([4.6673e-01, 5.3327e-01, 1.1786e-32], grad_fn=<SelectBackward0>)\n",
      "dataset/train/da/da_jad_15.avi : tensor([4.6440e-01, 5.3560e-01, 1.9633e-32], grad_fn=<SelectBackward0>)\n",
      "dataset/train/da/da_jad_11.avi : tensor([4.8680e-01, 5.1320e-01, 9.2521e-33], grad_fn=<SelectBackward0>)\n",
      "dataset/train/da/da_jad_10.avi : tensor([4.6960e-01, 5.3040e-01, 8.9262e-35], grad_fn=<SelectBackward0>)\n",
      "dataset/train/da/da_jad_12.avi : tensor([4.6460e-01, 5.3540e-01, 4.6658e-33], grad_fn=<SelectBackward0>)\n",
      "dataset/train/da/da_jad_13.avi : tensor([4.5573e-01, 5.4427e-01, 4.2781e-35], grad_fn=<SelectBackward0>)\n",
      "dataset/train/da/da_jad_8.avi : tensor([4.6812e-01, 5.3188e-01, 8.6124e-34], grad_fn=<SelectBackward0>)\n",
      "dataset/train/da/da_jad_9.avi : tensor([4.5094e-01, 5.4906e-01, 2.1832e-33], grad_fn=<SelectBackward0>)\n",
      "Training accuracy: 88.8888931274414%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "from models import McGurkPerceiver\n",
    "\n",
    "experiment = experiments[0]\n",
    "\n",
    "# Instantiate a Perceiver model for the given experiment\n",
    "model = McGurkPerceiver(experiment)\n",
    "\n",
    "# Train the model\n",
    "_, _, _, _ = model.train(epochs=50000, learning_rate=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                               "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([6.0985e-05, 9.9994e-01, 9.3509e-22], grad_fn=<SelectBackward0>)\n",
      "tensor([1.2057e-05, 9.9999e-01, 8.8424e-23], grad_fn=<SelectBackward0>)\n",
      "tensor([3.3384e-09, 4.9764e-01, 5.0236e-01], grad_fn=<SelectBackward0>)\n",
      "tensor([7.9002e-05, 9.9992e-01, 5.3723e-21], grad_fn=<SelectBackward0>)\n",
      "tensor([3.6814e-05, 9.9996e-01, 3.7259e-21], grad_fn=<SelectBackward0>)\n",
      "tensor([1.6922e-07, 1.0000e+00, 3.2978e-10], grad_fn=<SelectBackward0>)\n",
      "tensor([2.2273e-06, 1.0000e+00, 7.8300e-09], grad_fn=<SelectBackward0>)\n",
      "tensor([3.4839e-05, 9.9997e-01, 1.5959e-23], grad_fn=<SelectBackward0>)\n",
      "tensor([7.8473e-05, 9.9992e-01, 9.2750e-22], grad_fn=<SelectBackward0>)\n",
      "tensor([5.4733e-05, 9.9995e-01, 2.2401e-23], grad_fn=<SelectBackward0>)\n",
      "tensor([6.6586e-05, 9.9993e-01, 1.7997e-20], grad_fn=<SelectBackward0>)\n",
      "tensor([7.8024e-08, 9.9997e-01, 2.8087e-05], grad_fn=<SelectBackward0>)\n",
      "tensor([9.5818e-07, 1.0000e+00, 7.8007e-09], grad_fn=<SelectBackward0>)\n",
      "tensor([4.4217e-05, 9.9996e-01, 1.9184e-20], grad_fn=<SelectBackward0>)\n",
      "tensor([1.6417e-07, 9.9999e-01, 1.1204e-05], grad_fn=<SelectBackward0>)\n",
      "tensor([1.7187e-06, 1.0000e+00, 2.0033e-09], grad_fn=<SelectBackward0>)\n",
      "tensor([2.9455e-11, 1.0000e+00, 2.7448e-30], grad_fn=<SelectBackward0>)\n",
      "tensor([1.1143e-07, 1.0000e+00, 4.8072e-09], grad_fn=<SelectBackward0>)\n",
      "tensor([2.9657e-08, 1.0000e+00, 1.5085e-13], grad_fn=<SelectBackward0>)\n",
      "tensor([1.6968e-06, 1.0000e+00, 3.0659e-11], grad_fn=<SelectBackward0>)\n",
      "tensor([4.4238e-04, 9.9956e-01, 6.3774e-38], grad_fn=<SelectBackward0>)\n",
      "tensor([4.1004e-06, 1.0000e+00, 4.2401e-09], grad_fn=<SelectBackward0>)\n",
      "tensor([2.1969e-06, 1.0000e+00, 2.2396e-10], grad_fn=<SelectBackward0>)\n",
      "tensor([6.6026e-05, 9.9993e-01, 9.4573e-26], grad_fn=<SelectBackward0>)\n",
      "tensor([2.8318e-04, 9.9972e-01, 4.7325e-29], grad_fn=<SelectBackward0>)\n",
      "tensor([2.7742e-05, 9.9997e-01, 2.9248e-08], grad_fn=<SelectBackward0>)\n",
      "tensor([2.3321e-05, 9.9998e-01, 3.1189e-22], grad_fn=<SelectBackward0>)\n",
      "tensor([6.1899e-05, 9.9994e-01, 3.1331e-23], grad_fn=<SelectBackward0>)\n",
      "tensor([7.7433e-05, 9.9992e-01, 3.2779e-07], grad_fn=<SelectBackward0>)\n",
      "tensor([1.1115e-05, 9.9999e-01, 1.8099e-23], grad_fn=<SelectBackward0>)\n",
      "tensor([2.9012e-05, 9.9997e-01, 5.0714e-24], grad_fn=<SelectBackward0>)\n",
      "tensor([2.4931e-05, 9.9998e-01, 8.0663e-09], grad_fn=<SelectBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "# Test the model on McGurk effect videos\n",
    "predictions = model.test()\n",
    "\n",
    "# Print the results\n",
    "for i in range(len(predictions)):\n",
    "    print(predictions[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "mean() received an invalid combination of arguments - got (out=NoneType, dtype=NoneType, axis=int, ), but expected one of:\n * (*, torch.dtype dtype)\n * (tuple of ints dim, bool keepdim, *, torch.dtype dtype)\n * (tuple of names dim, bool keepdim, *, torch.dtype dtype)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/Users/jad/Academia/EPFL/CS433/ml-project2-mcgurk/main.ipynb Cell 4\u001b[0m line \u001b[0;36m7\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/jad/Academia/EPFL/CS433/ml-project2-mcgurk/main.ipynb#W3sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mnumpy\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mnp\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/jad/Academia/EPFL/CS433/ml-project2-mcgurk/main.ipynb#W3sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m \u001b[39m# Get the average confidence scores for each sound\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/jad/Academia/EPFL/CS433/ml-project2-mcgurk/main.ipynb#W3sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m predictions_avg \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mmean(predictions, axis\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/jad/Academia/EPFL/CS433/ml-project2-mcgurk/main.ipynb#W3sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m \u001b[39m# Plot the average confidence scores with x axis labels for each sound\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/jad/Academia/EPFL/CS433/ml-project2-mcgurk/main.ipynb#W3sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m plt\u001b[39m.\u001b[39mbar([experiment\u001b[39m.\u001b[39mauditory, experiment\u001b[39m.\u001b[39mvisual, experiment\u001b[39m.\u001b[39mmcgurk], predictions_avg)\n",
      "File \u001b[0;32m<__array_function__ internals>:200\u001b[0m, in \u001b[0;36mmean\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[0;32m~/.pyenv/versions/anaconda3-2023.07-0/lib/python3.11/site-packages/numpy/core/fromnumeric.py:3462\u001b[0m, in \u001b[0;36mmean\u001b[0;34m(a, axis, dtype, out, keepdims, where)\u001b[0m\n\u001b[1;32m   3460\u001b[0m         \u001b[39mpass\u001b[39;00m\n\u001b[1;32m   3461\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 3462\u001b[0m         \u001b[39mreturn\u001b[39;00m mean(axis\u001b[39m=\u001b[39maxis, dtype\u001b[39m=\u001b[39mdtype, out\u001b[39m=\u001b[39mout, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m   3464\u001b[0m \u001b[39mreturn\u001b[39;00m _methods\u001b[39m.\u001b[39m_mean(a, axis\u001b[39m=\u001b[39maxis, dtype\u001b[39m=\u001b[39mdtype,\n\u001b[1;32m   3465\u001b[0m                       out\u001b[39m=\u001b[39mout, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "\u001b[0;31mTypeError\u001b[0m: mean() received an invalid combination of arguments - got (out=NoneType, dtype=NoneType, axis=int, ), but expected one of:\n * (*, torch.dtype dtype)\n * (tuple of ints dim, bool keepdim, *, torch.dtype dtype)\n * (tuple of names dim, bool keepdim, *, torch.dtype dtype)\n"
     ]
    }
   ],
   "source": [
    "# Plot average of confidence scores for each sound\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Get the average confidence scores for each sound\n",
    "predictions_avg = np.mean(predictions, axis=0)\n",
    "\n",
    "# Plot the average confidence scores with x axis labels for each sound\n",
    "plt.bar([experiment.auditory, experiment.visual, experiment.mcgurk], predictions_avg)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
